{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e230c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import os\n",
    "import sys\n",
    "import librosa\n",
    "import copy\n",
    "import pickle\n",
    "from iteration_utilities import deepflatten\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "ROOT = '' # set\n",
    "sys.path.append(ROOT)\n",
    "\n",
    "import utils\n",
    "\n",
    "# change the width of the cells\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900afee0",
   "metadata": {},
   "source": [
    "# Spectrograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaf4a15",
   "metadata": {},
   "source": [
    "## UMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707c8616",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "show_bool = True # set\n",
    "\n",
    "DATA = os.path.join(ROOT, 'data', 'UMC')\n",
    "# pick the datasets\n",
    "datasets = ['DKMP_OLD', 'DKMP_UMC', 'RKMP_OLD', 'RKMP_UMC']\n",
    "# exclude noisy ids\n",
    "exclude_noisy = ['ID_12', 'ID_14', 'ID_24', 'ID_004', 'ID_007', 'ID_013', 'ID_3']\n",
    "# exclude bad\n",
    "exclude_bad = ['ID_17', 'ID_18', 'ID_21'] # # ID_17 and ID_18 only have one class; dekomp and rekomp for ID_21 are the same recording!\n",
    "\n",
    "# initialize the dictionaries\n",
    "all_data = {'data': [], \n",
    "            'label': [],\n",
    "            'frames':[],\n",
    "            'wav': [],\n",
    "            'id': [],\n",
    "            'sig_qual': [],\n",
    "            'excluded': []}\n",
    "\n",
    "lens=[]\n",
    "segs = []\n",
    "specs_for_normalization = []\n",
    "full_or_zeropad = ''\n",
    "spec_len = 2 #seconds\n",
    "fmin = 25\n",
    "fmax = 1000\n",
    "spec_frames = 128 # dimension\n",
    "# spec_frames = 64 # dimension\n",
    "# fmax = 400\n",
    "\n",
    "if spec_frames == 128:\n",
    "    # per channel means, used for normalization\n",
    "    specs_mean = -71.84363555908203\n",
    "    # per channel stds, used for normalization\n",
    "    specs_std = 13.924535751342773\n",
    "elif spec_frames == 64:\n",
    "    # per channel means, used for normalization\n",
    "    specs_mean = -58.466644287109375\n",
    "    # per channel stds, used for normalization\n",
    "    specs_std = 19.023942947387695\n",
    "for dataset in datasets:\n",
    "    print(f'Processing dataset {dataset}')\n",
    "    # read the names of the recordings in the folder\n",
    "    SEGMENTS = glob.glob(os.path.join(DATA, dataset, 'segments', '*.txt'))\n",
    "    segments = [os.path.basename(SEG) for SEG in SEGMENTS]\n",
    "    if dataset in ['DKMP_OLD', 'RKMP_OLD']:\n",
    "        recs = [f\"{rec.split('_')[0]}_{rec.split('_')[1]}\" for rec in segments]\n",
    "    elif dataset in ['DKMP_UMC', 'RKMP_UMC']:\n",
    "        recs = [f\"{rec.split('_')[0]}_{rec.split('_')[1]}_{rec.split('_')[2]}\" for rec in segments]\n",
    "    ids = [f\"ID_{rec.split('_')[0]}\" for rec in recs] \n",
    "    for rec, idx, SEG in zip(recs, ids, SEGMENTS):\n",
    "        # detetmine the label\n",
    "        if dataset in ['DKMP_OLD', 'DKMP_UMC']:\n",
    "            label = 1\n",
    "        elif dataset in ['RKMP_OLD', 'RKMP_UMC']:\n",
    "            label = 0\n",
    "        # determine the signal quality\n",
    "        if idx in exclude_noisy:\n",
    "            sig_qual = 0\n",
    "        else:\n",
    "            sig_qual = 1\n",
    "        # determine if excluded\n",
    "        if idx in exclude_bad:\n",
    "            excluded = 0\n",
    "        else:\n",
    "            excluded = 1\n",
    "        states = np.loadtxt(SEG)\n",
    "        frames = np.where(states[:-1] != states[1:])[0]\n",
    "        frames+=1\n",
    "        states = [states[f] for f in frames]\n",
    "        # find the start of each segment\n",
    "        seg_starts = []\n",
    "        for i, (frame, state) in enumerate(zip(frames, states)):\n",
    "            # if cycle does not end abruptly\n",
    "            if state == 1 and 1 in states[i+1:]:\n",
    "                seg_states = states[i:i+4]\n",
    "                if seg_states != [1, 2, 3, 4]:\n",
    "                    raise Exception('Segment states are not correct!')\n",
    "                seg_starts.append(i)\n",
    "                seg_frames = frames[i:i+5] - frames[i] # include the start of the next segment, so we know the length of this segment\n",
    "                all_data['label'].append(label)\n",
    "                #all_data['frames'].append(seg_frames)\n",
    "                all_data['wav'].append(rec)\n",
    "                all_data['id'].append(idx)\n",
    "                all_data['sig_qual'].append(sig_qual)\n",
    "                all_data['excluded'].append(excluded)\n",
    "        # save segments for each of the frequency bands         \n",
    "        FREQ = os.path.join(DATA, dataset, f'raw')\n",
    "        WAV = os.path.join(FREQ, f'{rec}.wav')\n",
    "        y, sr = librosa.load(WAV, sr=None)\n",
    "        # compute mel power spectrogram\n",
    "        hop_length = int(sr*spec_len/spec_frames)\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y=y, \n",
    "                                                     sr=sr, \n",
    "                                                     n_fft=hop_length*4, \n",
    "                                                     hop_length=hop_length, \n",
    "                                                     n_mels=spec_frames,\n",
    "                                                     fmin=fmin, \n",
    "                                                     fmax=fmax\n",
    "                                                        )\n",
    "        # convert to dB scale\n",
    "        mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "        # save to calculate normalization values\n",
    "        specs_for_normalization.append(mel_spectrogram_db)\n",
    "        #sigs_for_normalization.append(y)\n",
    "        \n",
    "        # normalize the spectrogram\n",
    "        mel_spectrogram_db = (mel_spectrogram_db-specs_mean)/specs_std\n",
    "        \n",
    "        frames_spec = [round(f*mel_spectrogram_db.shape[1]/len(y)) for f in frames]\n",
    "        \n",
    "        for start in seg_starts:\n",
    "            seg_states = states[start:start+4]\n",
    "            seg_frames = frames[start:start+5] - frames[start]\n",
    "            seg_frames_spec = np.array(frames_spec[start:start+5]) - frames_spec[start]\n",
    "            # cut spec\n",
    "            seg_y = y[frames[start]:frames[start+4]]\n",
    "            # spectrogram segment\n",
    "            spec = mel_spectrogram_db[:, frames_spec[start]:frames_spec[start+4]]\n",
    "            # zero pad the timeseries\n",
    "            if len(seg_y) > 8000:\n",
    "                print(f'{rec} segment {start} is longer than 2000 samples')\n",
    "            seg_y = copy.deepcopy(seg_y)\n",
    "            seg_y.resize(8000)\n",
    "            # zero pad spectrogram\n",
    "            pad_size = ((0, 0), (0, max(0, spec_frames - spec.shape[1])))\n",
    "            spec = np.pad(spec, pad_size, mode='constant')\n",
    "            if show_bool:\n",
    "                # Plot the spectrograms and timeseries with frames to see if everything is OK\n",
    "                plt.figure(figsize=(4, 4))\n",
    "                plt.imshow(spec)\n",
    "                plt.axvline(x=seg_frames_spec[0], color = 'red')\n",
    "                plt.axvline(x=seg_frames_spec[1], color = 'black')\n",
    "                plt.axvline(x=seg_frames_spec[2], color = 'black')\n",
    "                plt.axvline(x=seg_frames_spec[3], color = 'black')\n",
    "                plt.yticks([])\n",
    "                plt.xlim((0, len(spec[0])))\n",
    "                plt.show()\n",
    "                plt.close()\n",
    "                plt.figure(figsize=(4, 4))\n",
    "                plt.plot(seg_y)\n",
    "                plt.axvline(x=seg_frames[0], color = 'red')\n",
    "                plt.axvline(x=seg_frames[1], color = 'black')\n",
    "                plt.axvline(x=seg_frames[2], color = 'black')\n",
    "                plt.axvline(x=seg_frames[3], color = 'black')\n",
    "                plt.yticks([])\n",
    "                plt.xlim((0, len(seg_y)))\n",
    "                plt.show()\n",
    "                plt.close()\n",
    "                print()\n",
    "            all_data['data'].append(spec)\n",
    "            all_data['frames'].append(seg_frames_spec)\n",
    "            \n",
    "# Sanity check for the normalization values\n",
    "total_len = np.sum([len(x[0]) for x in specs_for_normalization])\n",
    "specs_for_normalization_flattened = [arr.flatten() for arr in specs_for_normalization]\n",
    "specs_for_normalization_flattened_combined = np.concatenate(specs_for_normalization_flattened)\n",
    "print(f'Data spectrogram mean: {specs_mean}')\n",
    "if np.mean(specs_for_normalization_flattened_combined) != specs_mean:\n",
    "    print(f'WARNING: Data mean is not the same as defined: {np.mean(specs_for_normalization_flattened_combined)}')\n",
    "    warnings.warn(f'WARNING: Data mean is not the same as defined: {np.mean(specs_for_normalization_flattened_combined)}')\n",
    "print(f'Data spectrogram std: {specs_std}')\n",
    "if np.std(specs_for_normalization_flattened_combined) != specs_std:\n",
    "    print(f'WARNING: Data std is not the same as defined: {np.std(specs_for_normalization_flattened_combined)}')\n",
    "    warnings.warn(f'WARNING: Data std is not the same as defined: {np.std(specs_for_normalization_flattened_combined)}')\n",
    "    \n",
    "\n",
    "DATASET = os.path.join(DATA, f'zbytes_UMC_dataset_spectrograms{spec_frames}.dat')\n",
    "utils.dict2file(all_data, DATASET)\n",
    "print(f'Dataset has been saved to {DATASET}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d261abd",
   "metadata": {},
   "source": [
    "## PhysioNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7e4da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = os.path.join(ROOT, 'data', 'physionet')\n",
    "\n",
    "# list the test wavs\n",
    "test_wavs = pd.read_csv(os.path.join(DATA, 'validation', 'REFERENCE.csv'), names=['rec', 'class'])['rec'].values\n",
    "# train wavs used as 100% of the train data in our experiments\n",
    "train_wavs = ['a0059', 'a0101', 'a0103', 'a0104', 'a0110', 'a0115', 'a0120', 'a0122', 'a0123', 'a0126', 'a0130', 'a0132', 'a0133', 'a0134', 'a0140', 'a0141', 'a0142', 'a0143', 'a0148', 'a0149', 'a0152', 'a0153', 'a0154', 'a0155', 'a0158', 'a0160', 'a0161', 'a0165', 'a0166', 'a0169', 'a0170', 'a0171', 'a0172', 'a0178', 'a0179', 'a0180', 'a0181', 'a0183', 'a0184', 'a0185', 'a0187', 'a0188', 'a0189', 'a0193', 'a0195', 'a0196', 'a0197', 'a0199', 'a0204', 'a0208', 'a0210', 'a0211', 'a0212', 'a0213', 'a0214', 'a0221', 'a0224', 'a0227', 'a0228', 'a0229', 'a0231', 'a0235', 'a0236', 'a0238', 'a0240', 'a0241', 'a0242', 'a0243', 'a0245', 'a0246', 'a0248', 'a0250', 'a0252', 'a0253', 'a0254', 'a0257', 'a0261', 'a0264', 'a0266', 'a0267', 'a0268', 'a0269', 'a0270', 'a0271', 'a0274', 'a0276', 'a0278', 'a0283', 'a0285', 'a0287', 'a0288', 'a0289', 'a0290', 'a0291', 'a0293', 'a0294', 'a0297', 'a0298', 'a0299', 'a0301', 'a0302', 'a0304', 'a0306', 'a0309', 'a0310', 'a0311', 'a0312', 'a0313', 'a0320', 'a0323', 'a0325', 'a0326', 'a0328', 'a0329', 'a0331', 'a0332', 'a0334', 'a0335', 'a0336', 'a0337', 'a0339', 'a0340', 'a0342', 'a0346', 'a0347', 'a0348', 'a0351', 'a0352', 'a0353', 'a0355', 'a0358', 'a0359', 'a0361', 'a0366', 'a0368', 'a0371', 'a0374', 'a0381', 'a0384', 'a0385', 'a0386', 'a0389', 'a0391', 'a0393', 'a0396', 'a0401', 'a0404', 'a0405', 'a0406', 'a0407', 'a0408', 'a0409', 'b0110', 'b0112', 'b0129', 'b0132', 'b0134', 'b0142', 'b0143', 'b0156', 'b0157', 'b0161', 'b0166', 'b0177', 'b0189', 'b0192', 'b0202', 'b0246', 'b0250', 'b0251', 'b0257', 'b0261', 'b0262', 'b0263', 'b0265', 'b0267', 'b0268', 'b0269', 'b0271', 'b0273', 'b0279', 'b0280', 'b0282', 'b0292', 'b0295', 'b0306', 'b0307', 'b0318', 'b0319', 'b0327', 'b0328', 'b0334', 'b0335', 'b0339', 'b0341', 'b0344', 'b0347', 'b0354', 'b0369', 'b0373', 'b0383', 'b0385', 'b0390', 'b0392', 'b0395', 'b0397', 'b0406', 'b0408', 'b0422', 'b0428', 'b0434', 'b0435', 'b0436', 'b0437', 'b0446', 'b0449', 'b0450', 'b0454', 'b0467', 'b0468', 'b0471', 'b0474', 'b0477', 'b0478', 'b0484', 'b0490', 'c0010', 'c0011', 'c0015', 'c0016', 'c0019', 'c0022', 'c0023', 'c0030', 'd0010', 'd0012', 'd0014', 'd0015', 'd0016', 'd0017', 'd0018', 'd0019', 'd0020', 'd0021', 'd0022', 'd0023', 'd0024', 'd0025', 'd0027', 'd0028', 'd0029', 'd0030', 'd0031', 'd0032', 'd0033', 'd0034', 'd0035', 'd0036', 'd0037', 'd0038', 'd0039', 'd0040', 'd0041', 'd0042', 'd0043', 'd0045', 'd0046', 'd0047', 'd0048', 'd0049', 'd0050', 'd0051', 'd0052', 'd0053', 'd0054', 'd0055', 'e00074', 'e00254', 'e00277', 'e00309', 'e00347', 'e00354', 'e00365', 'e00387', 'e00419', 'e00425', 'e00436', 'e00453', 'e00480', 'e00493', 'e00509', 'e00512', 'e00531', 'e00552', 'e00559', 'e00566', 'e00568', 'e00569', 'e00580', 'e00600', 'e00613', 'e00645', 'e00652', 'e00658', 'e00686', 'e00693', 'e00696', 'e00699', 'e00703', 'e00710', 'e00725', 'e00726', 'e00739', 'e00744', 'e00765', 'e00766', 'e00792', 'e00799', 'e00808', 'e00811', 'e00818', 'e00824', 'e00841', 'e00847', 'e00871', 'e00872', 'e00880', 'e00897', 'e00908', 'e00914', 'e00917', 'e00925', 'e00926', 'e00929', 'e00936', 'e00967', 'e00974', 'e00980', 'e00998', 'e01013', 'e01016', 'e01055', 'e01062', 'e01072', 'e01073', 'e01075', 'e01084', 'e01097', 'e01105', 'e01115', 'e01148', 'e01160', 'e01177', 'e01198', 'e01205', 'e01215', 'e01225', 'e01226', 'e01245', 'e01246', 'e01247', 'e01252', 'e01253', 'e01256', 'e01263', 'e01272', 'e01276', 'e01283', 'e01284', 'e01289', 'e01291', 'e01295', 'e01299', 'e01308', 'e01324', 'e01336', 'e01341', 'e01351', 'e01358', 'e01367', 'e01369', 'e01374', 'e01375', 'e01376', 'e01382', 'e01383', 'e01392', 'e01399', 'e01401', 'e01416', 'e01421', 'e01433', 'e01457', 'e01461', 'e01474', 'e01479', 'e01487', 'e01489', 'e01493', 'e01494', 'e01511', 'e01525', 'e01531', 'e01537', 'e01551', 'e01559', 'e01572', 'e01581', 'e01601', 'e01602', 'e01605', 'e01618', 'e01623', 'e01625', 'e01638', 'e01651', 'e01661', 'e01663', 'e01665', 'e01666', 'e01668', 'e01686', 'e01688', 'e01689', 'e01697', 'e01698', 'e01711', 'e01719', 'e01728', 'e01734', 'e01748', 'e01753', 'e01756', 'e01766', 'e01767', 'e01787', 'e01791', 'e01800', 'e01808', 'e01812', 'e01824', 'e01825', 'e01832', 'e01846', 'e01848', 'e01851', 'e01855', 'e01856', 'e01857', 'e01867', 'e01869', 'e01873', 'e01881', 'e01917', 'e01922', 'e01924', 'e01929', 'e01938', 'e01953', 'e01959', 'e01962', 'e01967', 'e01971', 'e01978', 'e02001', 'e02010', 'e02015', 'e02017', 'e02030', 'e02032', 'e02044', 'e02045', 'e02055', 'e02058', 'e02059', 'e02065', 'e02074', 'e02085', 'e02088', 'e02092', 'e02097', 'e02101', 'e02102', 'e02108', 'e02111', 'e02117', 'e02121', 'e02126', 'e02133', 'e02135', 'e02137', 'e02140', 'f0003', 'f0007', 'f0008', 'f0011', 'f0012', 'f0015', 'f0016', 'f0017', 'f0018', 'f0020', 'f0022', 'f0023', 'f0027', 'f0029', 'f0031', 'f0035', 'f0036', 'f0041', 'f0042', 'f0045', 'f0047', 'f0048', 'f0050', 'f0052', 'f0054', 'f0056', 'f0060', 'f0063', 'f0064', 'f0065', 'f0066', 'f0067', 'f0068', 'f0069', 'f0070', 'f0071', 'f0072', 'f0075', 'f0076', 'f0078', 'f0079', 'f0080', 'f0081', 'f0082', 'f0083', 'f0085', 'f0090', 'f0091', 'f0092', 'f0093', 'f0096', 'f0097', 'f0098', 'f0099', 'f0100', 'f0101', 'f0103', 'f0106', 'f0109', 'f0112', 'f0113', 'f0114']\n",
    "# list the datasets\n",
    "datasets = ['a', 'b', 'c', 'd', 'e', 'f']\n",
    "# mean and std for normalization \n",
    "train_mean = -59.606563568115234\n",
    "train_std = 15.96771240234375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c948804a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# initialize the dictionaries\n",
    "train_data = {'data': [], \n",
    "              'label': [],\n",
    "              'frames':[],\n",
    "              'wav': [],\n",
    "              'sig_qual': []}\n",
    "test_data = {'data': [],\n",
    "             'label': [],\n",
    "             'frames':[],\n",
    "             'wav': [],\n",
    "             'sig_qual': []}\n",
    "\n",
    "specs_for_normalization = []\n",
    "sigs_for_normalization = []\n",
    "lens=[]\n",
    "segs = []\n",
    "spec_len = 2.2 # seconds\n",
    "fmin = 25\n",
    "fmax = 1000\n",
    "spec_frames = 128 # dimension\n",
    "desired_frame_rate = spec_frames / spec_len  # 128 frames for every 2.2 seconds\n",
    "for dataset in datasets:\n",
    "    print(f'Processing dataset {dataset}')\n",
    "    # read the reference file with the recording names, labels, and signal quality\n",
    "    REF = os.path.join(DATA, 'annotations', 'updated', f'training-{dataset}', 'REFERENCE_withSQI.csv')\n",
    "    ref_df = pd.read_csv(REF, names=['rec', 'class', 'sig_quality']) #class: 1 for abnormal and -1 for normal; sig_qual: 0 for bad quality 1 for good quality\n",
    "    wavs = ref_df['rec']\n",
    "    labels = ref_df['class']\n",
    "    sig_quals = ref_df['sig_quality']\n",
    "    for wav, label, sig_qual in zip(wavs, labels, sig_quals):\n",
    "        if wav not in list(test_wavs) + train_wavs:\n",
    "            continue\n",
    "        # segmentations for 'e00001', 'e00032', 'e00039', 'e00044' are missing\n",
    "        # change labels to 0 for normal and 1 for abnormal\n",
    "        if label == -1:\n",
    "            label = 0\n",
    "        if sig_qual == 1:\n",
    "            ANNOT = os.path.join(DATA, 'annotations', 'hand_corrected', f'training-{dataset}_StateAns') # hand corrected\n",
    "            wav_annot = scipy.io.loadmat(os.path.join(ANNOT, f'{wav}_StateAns.mat'))\n",
    "            wav_annot_states = wav_annot['state_ans']\n",
    "        elif sig_qual == 0:\n",
    "            ANNOT = os.path.join(DATA, 'annotations', 'springer_alg', f'training-{dataset}-Aut') # springer algorithm\n",
    "            wav_annot = scipy.io.loadmat(os.path.join(ANNOT, f'{wav}_StateAns0.mat'))\n",
    "            wav_annot_states = wav_annot['state_ans0']\n",
    "        else:\n",
    "            raise Exception('Signal quality has not been determined!') \n",
    "        # convert to pandas dataframe, then flatten\n",
    "        df_wav_annot_states = pd.DataFrame(wav_annot_states, columns = ['frame', 'state'])\n",
    "        frames = df_wav_annot_states['frame'].values\n",
    "        frames = list(deepflatten(frames))\n",
    "        fr = copy.deepcopy(frames)\n",
    "        states = df_wav_annot_states['state']\n",
    "        states = list(deepflatten(states, ignore=str))\n",
    "        # find the start of each segment\n",
    "        seg_starts = []\n",
    "        for i, (frame, state) in enumerate(zip(frames, states)):  \n",
    "            if state not in ['S1', 'systole', 'S2', 'diastole']:\n",
    "                print(f'{wav}, {label=}, {sig_qual=}, {state=}, {fr[i]}')\n",
    "            # if cycle does not end abruptly\n",
    "            if state == 'S1' and 'S1' in states[i+1:]:\n",
    "                seg_states = states[i:i+4]\n",
    "                # skip if there is noise in this segment\n",
    "                if 'N' in ''.join(seg_states):\n",
    "                    print('Skip:')\n",
    "                    print(f'\\t{wav}, {label=}, {sig_qual=}, {state=}, {fr[i]}')\n",
    "                    print(f'\\t{seg_states}, frames:{fr[i:i+4]}')\n",
    "                    continue\n",
    "                if seg_states != ['S1', 'systole', 'S2', 'diastole']:\n",
    "                    raise Exception('Segment states are not correct!')\n",
    "                seg_starts.append(i)\n",
    "                seg_frames = frames[i:i+5] - frames[i] # include the start of the next segment, so we know the length of this segment\n",
    "        # to measure the lengths\n",
    "        for start in seg_starts:\n",
    "            seg_frames = frames[start:start+5] - frames[start]\n",
    "            lens.append(seg_frames[-1]-seg_frames[0])\n",
    "        # save segments\n",
    "        FREQ = os.path.join(DATA, f'training-{dataset}', f'raw')\n",
    "        WAV = os.path.join(FREQ, f'{wav}.wav')\n",
    "        y, sr = librosa.load(WAV, sr=None)\n",
    "        # compute mel power spectrogram\n",
    "        hop_length = int(sr*spec_len/spec_frames)\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y=y, \n",
    "                                                     sr=sr, \n",
    "                                                     n_fft=hop_length*4, \n",
    "                                                     hop_length=hop_length, \n",
    "                                                     n_mels=spec_frames,\n",
    "                                                     fmin=25, \n",
    "                                                     fmax=1000\n",
    "                                                        )\n",
    "        # convert to dB scale\n",
    "        mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "        # save to calculate normalization values\n",
    "        if wav in train_wavs:\n",
    "            specs_for_normalization.append(mel_spectrogram_db)\n",
    "            sigs_for_normalization.append(y)\n",
    "        # normalize the spectrogram\n",
    "        mel_spectrogram_db = (mel_spectrogram_db-train_mean)/train_std\n",
    "        #frames_spec = [frame/(sr*spec_len/spec_frames) for frame in frames] # CAREFULL, THIS PRODUCES WRONG RESULTS!!!\n",
    "        frames_spec = [round(f*mel_spectrogram_db.shape[1]/len(y)) for f in frames]\n",
    "        if wav in []:\n",
    "            # Plot the spectrograms and timeseries with frames to see if everything is OK\n",
    "            plt.figure(figsize=(20, 4))\n",
    "            plt.imshow(mel_spectrogram_db)\n",
    "            for start in seg_starts:\n",
    "                plt.axvline(x=frames_spec[start], color = 'red')\n",
    "                plt.axvline(x=frames_spec[start+1], color = 'black')\n",
    "                plt.axvline(x=frames_spec[start+2], color = 'black')\n",
    "                plt.axvline(x=frames_spec[start+3], color = 'black')\n",
    "            plt.yticks([])\n",
    "            plt.xlim((0, len(mel_spectrogram_db[0])))\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            plt.figure(figsize=(20, 4))\n",
    "            plt.plot(y)\n",
    "            for start in seg_starts:\n",
    "                plt.axvline(x=frames[start], color = 'red')\n",
    "                plt.axvline(x=frames[start+1], color = 'black')\n",
    "                plt.axvline(x=frames[start+2], color = 'black')\n",
    "                plt.axvline(x=frames[start+3], color = 'black')\n",
    "            plt.yticks([])\n",
    "            plt.xlim((0, len(y)))\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            print()\n",
    "        for start in seg_starts:\n",
    "            seg_states = states[start:start+4]\n",
    "            seg_frames = frames[start:start+5] - frames[start]\n",
    "            seg_frames_spec = np.array(frames_spec[start:start+5]) - frames_spec[start]\n",
    "            # cut spec\n",
    "            seg_y = y[frames[start]:frames[start+4]]\n",
    "            # spectrogram segment\n",
    "            spec = mel_spectrogram_db[:, frames_spec[start]:frames_spec[start+4]]\n",
    "            # zero pad the timeseries\n",
    "            if len(seg_y) > 4400:\n",
    "                print(f'{wav} segment {start} is longer than 2500 samples')\n",
    "            seg_y = copy.deepcopy(seg_y)\n",
    "            seg_y.resize(4400)\n",
    "            # zero pad spectrogram\n",
    "            pad_size = ((0, 0), (0, max(0, spec_frames - spec.shape[1])))\n",
    "            spec = np.pad(spec, pad_size, mode='constant')\n",
    "            if wav in []:\n",
    "                # Plot the spectrograms and timeseries with frames to see if everything is OK\n",
    "                plt.figure(figsize=(4, 4))\n",
    "                plt.imshow(spec)\n",
    "                plt.axvline(x=seg_frames_spec[0], color = 'red')\n",
    "                plt.axvline(x=seg_frames_spec[1], color = 'black')\n",
    "                plt.axvline(x=seg_frames_spec[2], color = 'black')\n",
    "                plt.axvline(x=seg_frames_spec[3], color = 'black')\n",
    "                plt.yticks([])\n",
    "                plt.xlim((0, len(spec[0])))\n",
    "                plt.show()\n",
    "                plt.close()\n",
    "                plt.figure(figsize=(4, 4))\n",
    "                plt.plot(seg_y)\n",
    "                plt.axvline(x=seg_frames[0], color = 'red')\n",
    "                plt.axvline(x=seg_frames[1], color = 'black')\n",
    "                plt.axvline(x=seg_frames[2], color = 'black')\n",
    "                plt.axvline(x=seg_frames[3], color = 'black')\n",
    "                plt.yticks([])\n",
    "                plt.xlim((0, len(seg_y)))\n",
    "                plt.show()\n",
    "                plt.close()\n",
    "                print()\n",
    "            if wav in test_wavs:\n",
    "                test_data['data'].append(spec)\n",
    "                test_data['frames'].append(seg_frames_spec)\n",
    "                test_data['label'].append(label)\n",
    "                test_data['wav'].append(wav)\n",
    "                test_data['sig_qual'].append(sig_qual)\n",
    "            elif wav in train_wavs:\n",
    "                train_data['data'].append(spec)\n",
    "                train_data['frames'].append(seg_frames_spec)\n",
    "                train_data['label'].append(label)\n",
    "                train_data['wav'].append(wav)\n",
    "                train_data['sig_qual'].append(sig_qual)\n",
    "                \n",
    "# Sanity check for the normalization values\n",
    "total_len = np.sum([len(x[0]) for x in specs_for_normalization])\n",
    "specs_for_normalization_flattened = [arr.flatten() for arr in specs_for_normalization]\n",
    "specs_for_normalization_flattened_combined = np.concatenate(specs_for_normalization_flattened)\n",
    "print(f'Train data spectrogram mean: {train_mean}')\n",
    "if np.mean(specs_for_normalization_flattened_combined) != train_mean:\n",
    "    print(f'WARNING: Train mean is not the same as defined: {np.mean(specs_for_normalization_flattened_combined)}')\n",
    "    warnings.warn(f'WARNING: Train mean is not the same as defined: {np.mean(specs_for_normalization_flattened_combined)}')\n",
    "print(f'Train data spectrogram std: {train_std}')\n",
    "if np.std(specs_for_normalization_flattened_combined) != train_std:\n",
    "    print(f'WARNING: Train std is not the same as defined: {np.std(specs_for_normalization_flattened_combined)}')\n",
    "    warnings.warn(f'WARNING: Train std is not the same as defined: {np.std(specs_for_normalization_flattened_combined)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a650f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "DATASET = os.path.join(DATA, f'zbytes_physionet_spectrograms{spec_frames}_dataset_selection.dat')\n",
    "dataset = {'train':train_data, 'test':test_data}\n",
    "utils.dict2file(dataset, DATASET)\n",
    "print(f'Dataset has been saved to {DATASET}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4076dbe7",
   "metadata": {},
   "source": [
    "# Timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f73b35",
   "metadata": {},
   "source": [
    "## UMC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac30114d",
   "metadata": {},
   "source": [
    "### UMC databuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7238a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = os.path.join(ROOT, 'data', 'UMC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3698ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the datasets\n",
    "datasets = ['DKMP_OLD', 'DKMP_UMC', 'RKMP_OLD', 'RKMP_UMC']\n",
    "# select the frequency bands / channels\n",
    "freq_bands = ['25-45', '45-80', '80-200', '200-400', '25-400']\n",
    "# per channel means, used for normalization\n",
    "pc_means = [-0.00070414954, -0.00070995715, -0.0015120364, -0.013083812, -0.00044722442]\n",
    "# per channel stds, used for normalization\n",
    "pc_stds = [0.10012293, 0.09927997, 0.097917296, 0.11611214, 0.09939657]\n",
    "# exclude noisy ids\n",
    "exclude_noisy = ['ID_12', 'ID_14', 'ID_24', 'ID_004', 'ID_007', 'ID_013', 'ID_3']\n",
    "# exclude bad\n",
    "exclude_bad = ['ID_17', 'ID_18', 'ID_21'] # # ID_17 and ID_18 only have one class; dekomp and rekomp for ID_21 are the same recording!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ce5a77",
   "metadata": {},
   "source": [
    "#### Zero-padding approach (one heart cycle per segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94a0f76",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# initialize the dictionaries\n",
    "data_freq_bands = {}\n",
    "for freq_band in freq_bands:\n",
    "    data_freq_bands[freq_band] = []\n",
    "all_data = {'data': copy.deepcopy(data_freq_bands), \n",
    "            'label': [],\n",
    "            'frames':[],\n",
    "            'wav': [],\n",
    "            'id': [],\n",
    "            'sig_qual': [],\n",
    "            'excluded': []}\n",
    "\n",
    "lens=[]\n",
    "segs = []\n",
    "full_or_zeropad = ''\n",
    "for dataset in datasets:\n",
    "    print(f'Processing dataset {dataset}')\n",
    "    # read the names of the recordings in the folder\n",
    "    SEGMENTS = glob.glob(os.path.join(DATA, dataset, 'segments', '*.txt'))\n",
    "    segments = [os.path.basename(SEG) for SEG in SEGMENTS]\n",
    "    if dataset in ['DKMP_OLD', 'RKMP_OLD']:\n",
    "        recs = [f\"{rec.split('_')[0]}_{rec.split('_')[1]}\" for rec in segments]\n",
    "    elif dataset in ['DKMP_UMC', 'RKMP_UMC']:\n",
    "        recs = [f\"{rec.split('_')[0]}_{rec.split('_')[1]}_{rec.split('_')[2]}\" for rec in segments]\n",
    "    ids = [f\"ID_{rec.split('_')[0]}\" for rec in recs]   \n",
    "    for rec, idx, SEG in zip(recs, ids, SEGMENTS):\n",
    "        # detetmine the label\n",
    "        if dataset in ['DKMP_OLD', 'DKMP_UMC']:\n",
    "            label = 0\n",
    "        elif dataset in ['RKMP_OLD', 'RKMP_UMC']:\n",
    "            label = 1\n",
    "        # determine the signal quality\n",
    "        if idx in exclude_noisy:\n",
    "            sig_qual = 0\n",
    "        else:\n",
    "            sig_qual = 1\n",
    "        # determine if excluded\n",
    "        if idx in exclude_bad:\n",
    "            excluded = 0\n",
    "        else:\n",
    "            excluded = 1\n",
    "        states = np.loadtxt(SEG)\n",
    "        frames = np.where(states[:-1] != states[1:])[0]\n",
    "        frames+=1\n",
    "        states = [states[f] for f in frames]\n",
    "        # find the start of each segment\n",
    "        frames = [f//4 for f in frames] # downsample from 4000 to 1000Hz\n",
    "        seg_starts = []\n",
    "        for i, (frame, state) in enumerate(zip(frames, states)):\n",
    "            # if cycle does not end abruptly\n",
    "            if state == 1 and 1 in states[i+1:]:\n",
    "                seg_states = states[i:i+4]\n",
    "                if seg_states != [1, 2, 3, 4]:\n",
    "                    raise Exception('Segment states are not correct!')\n",
    "                seg_starts.append(i)\n",
    "                seg_frames = frames[i:i+5] - frames[i] # include the start of the next segment, so we know the length of this segment\n",
    "                all_data['label'].append(label)\n",
    "                all_data['frames'].append(seg_frames)\n",
    "                all_data['wav'].append(rec)\n",
    "                all_data['id'].append(idx)\n",
    "                all_data['sig_qual'].append(sig_qual)\n",
    "                all_data['excluded'].append(excluded)\n",
    "        # save segments for each of the frequency bands         \n",
    "        for freq_band, pc_mean, pc_std in zip(freq_bands, pc_means, pc_stds):\n",
    "#             if freq_band != '25-400':\n",
    "#                 continue\n",
    "            FREQ = os.path.join(DATA, dataset, f'raw_filtBandIIR(ZP)4-{freq_band}_normRMS')\n",
    "            WAV = os.path.join(FREQ, f'{rec}_filtBandIIR(ZP)4-{freq_band}_normRMS.wav')\n",
    "            y, _ = librosa.load(WAV, sr = 4000)\n",
    "            y_hat = librosa.resample(y=y, orig_sr=4000, target_sr=1000)\n",
    "            # normalize the recording using mean and std of the train data that were calculated in advance and are now hardcoded\n",
    "            y_hat = (y_hat-pc_mean) / pc_std\n",
    "            c=0\n",
    "            for start in seg_starts:\n",
    "                #seg_states = states[start:start+4]\n",
    "                seg_frames = frames[start:start+5] - frames[start]\n",
    "                seg_y = y_hat[frames[start]:frames[start+4]]\n",
    "                # zero pad the segments\n",
    "                if len(seg_y) > 2000:\n",
    "                    print(f'{rec} segment {start} is longer than 2000 samples')\n",
    "                seg_y = copy.deepcopy(seg_y)\n",
    "                seg_y.resize(2000)\n",
    "                all_data['data'][freq_band].append(seg_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaf78ea",
   "metadata": {},
   "source": [
    "### Per channel normalization values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d70eded",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "stds = []\n",
    "# Find mean and std of the train data of the NOT-ZERO-PADDED train data\n",
    "for key in all_data['data']:\n",
    "    freq_band = all_data['data'][key]\n",
    "    freq_band = np.concatenate(freq_band).ravel()\n",
    "    mean = np.mean(freq_band)\n",
    "    means.append(mean)\n",
    "    std = np.std(freq_band)\n",
    "    stds.append(std)\n",
    "print(f'Per channel means: {means}')\n",
    "print(f'Per channel standard deviations: {stds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d9c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "DATASET = os.path.join(DATA, f'zbytes_UMC_dataset{full_or_zeropad}.dat')\n",
    "dataset = all_data\n",
    "utils.dict2file(dataset, DATASET)\n",
    "print(f'Dataset has been saved to {DATASET}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157ccab4",
   "metadata": {},
   "source": [
    "## PhysioNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505070e5",
   "metadata": {},
   "source": [
    "### PhysioNet databuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739b97d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = os.path.join(ROOT, 'data', 'physionet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b855510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the test wavs\n",
    "test_wavs = pd.read_csv(os.path.join(DATA, 'validation', 'REFERENCE.csv'), names=['rec', 'class'])['rec'].values\n",
    "# pick the datasets\n",
    "datasets = ['a', 'b', 'c', 'd', 'e', 'f']\n",
    "# select the frequency bands / channels\n",
    "freq_bands = ['25-45', '45-80', '80-200', '200-400', '400-600', '600-1000', '25-400', '25-1000']\n",
    "# per channel means, used for normalization\n",
    "pc_means = [-8.522174e-05, -9.561972e-05, -0.0001494191, -0.00080938824, -0.0025577587, -0.0001152527, -5.2299594e-05, -1.4092535e-05]\n",
    "# per channel stds, used for normalization\n",
    "pc_stds = [0.09962083, 0.09932303, 0.097970456, 0.095019236, 0.052084293, 0.004212678, 0.09908513, 0.06640719]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11168670",
   "metadata": {},
   "source": [
    "#### Multiple heart cycles per segment approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db4fa08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# initialize the dictionaries\n",
    "data_freq_bands = {}\n",
    "for freq_band in freq_bands:\n",
    "    data_freq_bands[freq_band] = []\n",
    "train_data = {'data': copy.deepcopy(data_freq_bands), \n",
    "              'label': [],\n",
    "              'frames':[],\n",
    "              'wav': [],\n",
    "              'sig_qual': []}\n",
    "test_data = {'data': copy.deepcopy(data_freq_bands),\n",
    "             'label': [],\n",
    "             'frames':[],\n",
    "             'wav': [],\n",
    "             'sig_qual': []}\n",
    "\n",
    "segment_length = 2500\n",
    "lens=[]\n",
    "segs = []\n",
    "full_or_zeropad = '_full'\n",
    "for dataset in datasets:\n",
    "    print(f'Processing dataset {dataset}')\n",
    "    # read the reference file with the recording names, labels, and signal quality\n",
    "    REF = os.path.join(DATA, 'annotations', 'updated', f'training-{dataset}', 'REFERENCE_withSQI.csv')\n",
    "    ref_df = pd.read_csv(REF, names=['rec', 'class', 'sig_quality']) #class: 1 for abnormal and -1 for normal; sig_qual: 0 for bad quality 1 for good quality\n",
    "    wavs = ref_df['rec']\n",
    "    labels = ref_df['class']\n",
    "    sig_quals = ref_df['sig_quality']\n",
    "    for wav, label, sig_qual in zip(wavs, labels, sig_quals):\n",
    "        ### segmentations for 'e00001', 'e00032', 'e00039', 'e00044' are missing\n",
    "        # change labels to 0 for normal and 1 for abnormal\n",
    "        if label == -1:\n",
    "            label = 0\n",
    "        if sig_qual == 1:\n",
    "            ANNOT = os.path.join(DATA, 'annotations', 'hand_corrected', f'training-{dataset}_StateAns') # hand corrected\n",
    "            wav_annot = scipy.io.loadmat(os.path.join(ANNOT, f'{wav}_StateAns.mat'))\n",
    "            wav_annot_states = wav_annot['state_ans']\n",
    "        elif sig_qual == 0:\n",
    "            ANNOT = os.path.join(DATA, 'annotations', 'springer_alg', f'training-{dataset}-Aut') # springer algorithm\n",
    "            wav_annot = scipy.io.loadmat(os.path.join(ANNOT, f'{wav}_StateAns0.mat'))\n",
    "            wav_annot_states = wav_annot['state_ans0']\n",
    "        else:\n",
    "            raise Exception('Signal quality has not been determined!') \n",
    "        # convert to pandas dataframe, then flatten\n",
    "        df_wav_annot_states = pd.DataFrame(wav_annot_states, columns = ['frame', 'state'])\n",
    "        frames = df_wav_annot_states['frame'].values\n",
    "        frames = list(deepflatten(frames))\n",
    "        fr = copy.deepcopy(frames)\n",
    "        frames = [x//2 for x in frames] # downsample from 2000 to 1000Hz\n",
    "        states = df_wav_annot_states['state']\n",
    "        states = list(deepflatten(states, ignore=str))\n",
    "        # find the start of each segment\n",
    "        FREQ = os.path.join(DATA, f'training-{dataset}', f'raw_filtBandIIR(ZP)4-25-400_normRMS')\n",
    "        WAV = os.path.join(FREQ, f'{wav}_filtBandIIR(ZP)4-25-400_normRMS.wav')\n",
    "        y, _ = librosa.load(WAV, sr = 2000)\n",
    "        y = librosa.resample(y=y, orig_sr=2000, target_sr=1000)\n",
    "        seg_starts = []\n",
    "        seg_starts_frames = [] \n",
    "        for i, (frame, state) in enumerate(zip(frames, states)):  \n",
    "            if i == 0 and state == 'S1':\n",
    "                # skip as the first state is never full/is always clipped\n",
    "                continue\n",
    "            if state not in ['S1', 'systole', 'S2', 'diastole']:\n",
    "                # print to see which states are \"noise\"\n",
    "                print(f'{wav}, {label=}, {sig_qual=}, {state=}, {fr[i]}')\n",
    "            if state == 'S1' and 'S1' in states[i+1:]:\n",
    "                # the cycle starting here must not end abruptly (at least one whole cycle)\n",
    "                if len(y[frame:])< segment_length:\n",
    "                    # our segment is segment_length long\n",
    "                    continue\n",
    "                # find the index range of frames/segment that are included in that segment_length sample segment\n",
    "                last_i = i\n",
    "                for j in range(len(frames[i:])):\n",
    "                    if frames[j+i]-frames[i] <= segment_length:\n",
    "                        last_i = j+i\n",
    "                    else:\n",
    "                        break\n",
    "                seg_states = states[i:last_i+1]\n",
    "                # skip if there is noise in this segment\n",
    "                if 'N' in ''.join(seg_states):\n",
    "                    print('Skip:')\n",
    "                    print(f'\\t{wav}, {label=}, {sig_qual=}, {state=}, {fr[i]}')\n",
    "                    print(f'\\t{seg_states}, frames:{fr[i:last_i+1]}')\n",
    "                    continue\n",
    "                seg_starts.append(i)\n",
    "                seg_frames = frames[i:last_i+1] - frames[i] # shift so they start with 0\n",
    "                seg_frames = np.pad(seg_frames, (0, 28-len(seg_frames)), \"constant\", constant_values=-1) # 28 is max number of frames in our dataset\n",
    "                seg_starts_frames.append(seg_frames)\n",
    "                if wav in test_wavs:\n",
    "                    test_data['frames'].append(seg_frames)\n",
    "                    test_data['label'].append(label)\n",
    "                    test_data['wav'].append(wav)\n",
    "                    test_data['sig_qual'].append(sig_qual)\n",
    "                else:\n",
    "                    train_data['frames'].append(seg_frames)\n",
    "                    train_data['label'].append(label)\n",
    "                    train_data['wav'].append(wav)\n",
    "                    train_data['sig_qual'].append(sig_qual)\n",
    "        # save segments for each of the frequency bands         \n",
    "        for freq_band, pc_mean, pc_std in zip(freq_bands, pc_means, pc_stds):\n",
    "            FREQ = os.path.join(DATA, f'training-{dataset}', f'raw_filtBandIIR(ZP)4-{freq_band}_normRMS')\n",
    "            WAV = os.path.join(FREQ, f'{wav}_filtBandIIR(ZP)4-{freq_band}_normRMS.wav')\n",
    "            y, _ = librosa.load(WAV, sr = 2000)\n",
    "            y = librosa.resample(y=y, orig_sr=2000, target_sr=1000)\n",
    "            # normalize the recording using mean and std of the train data that were calculated in advance and are now hardcoded\n",
    "            y = (y-pc_mean) / pc_std\n",
    "            c=0\n",
    "            for start, seg_frames in zip(seg_starts, seg_starts_frames):\n",
    "                seg_y = y[frames[start]:frames[start]+segment_length]\n",
    "                if wav in test_wavs:\n",
    "                    test_data['data'][freq_band].append(seg_y)\n",
    "                else:\n",
    "                    train_data['data'][freq_band].append(seg_y)\n",
    "                if freq_band == '25-400':\n",
    "                    lens.append(len(seg_y))\n",
    "                    segs.append([wav, start])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c0f118",
   "metadata": {},
   "source": [
    "#### Zero-padding approach (one heart cycle per segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58bd497",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# initialize the dictionaries\n",
    "data_freq_bands = {}\n",
    "for freq_band in freq_bands:\n",
    "    data_freq_bands[freq_band] = []\n",
    "train_data = {'data': copy.deepcopy(data_freq_bands), \n",
    "              'label': [],\n",
    "              'frames':[],\n",
    "              'wav': [],\n",
    "              'sig_qual': []}\n",
    "test_data = {'data': copy.deepcopy(data_freq_bands),\n",
    "             'label': [],\n",
    "             'frames':[],\n",
    "             'wav': [],\n",
    "             'sig_qual': []}\n",
    "\n",
    "lens=[]\n",
    "segs = []\n",
    "full_or_zeropad = ''\n",
    "for dataset in datasets:\n",
    "    print(f'Processing dataset {dataset}')\n",
    "#     if dataset != 'a':\n",
    "#         continue\n",
    "    # read the reference file with the recording names, labels, and signal quality\n",
    "    REF = os.path.join(DATA, 'annotations', 'updated', f'training-{dataset}', 'REFERENCE_withSQI.csv')\n",
    "    ref_df = pd.read_csv(REF, names=['rec', 'class', 'sig_quality']) #class: 1 for abnormal and -1 for normal; sig_qual: 0 for bad quality 1 for good quality\n",
    "    wavs = ref_df['rec']\n",
    "    labels = ref_df['class']\n",
    "    sig_quals = ref_df['sig_quality']\n",
    "    for wav, label, sig_qual in zip(wavs, labels, sig_quals):\n",
    "        # segmentations for 'e00001', 'e00032', 'e00039', 'e00044' are missing\n",
    "        # change labels to 0 for normal and 1 for abnormal\n",
    "        if label == -1:\n",
    "            label = 0\n",
    "        if sig_qual == 1:\n",
    "            ANNOT = os.path.join(DATA, 'annotations', 'hand_corrected', f'training-{dataset}_StateAns') # hand corrected\n",
    "            wav_annot = scipy.io.loadmat(os.path.join(ANNOT, f'{wav}_StateAns.mat'))\n",
    "            wav_annot_states = wav_annot['state_ans']\n",
    "        elif sig_qual == 0:\n",
    "            ANNOT = os.path.join(DATA, 'annotations', 'springer_alg', f'training-{dataset}-Aut') # springer algorithm\n",
    "            wav_annot = scipy.io.loadmat(os.path.join(ANNOT, f'{wav}_StateAns0.mat'))\n",
    "            wav_annot_states = wav_annot['state_ans0']\n",
    "        else:\n",
    "            raise Exception('Signal quality has not been determined!') \n",
    "        # convert to pandas dataframe, then flatten\n",
    "        df_wav_annot_states = pd.DataFrame(wav_annot_states, columns = ['frame', 'state'])\n",
    "        frames = df_wav_annot_states['frame'].values\n",
    "        frames = list(deepflatten(frames))\n",
    "        fr = copy.deepcopy(frames)\n",
    "        frames = [x//2 for x in frames] # downsample from 2000 to 1000Hz\n",
    "        states = df_wav_annot_states['state']\n",
    "        states = list(deepflatten(states, ignore=str))\n",
    "        # find the start of each segment\n",
    "        seg_starts = []\n",
    "        for i, (frame, state) in enumerate(zip(frames, states)):  \n",
    "            if state not in ['S1', 'systole', 'S2', 'diastole']:\n",
    "                print(f'{wav}, {label=}, {sig_qual=}, {state=}, {fr[i]}')\n",
    "            # if cycle does not end abruptly\n",
    "            if state == 'S1' and 'S1' in states[i+1:]:\n",
    "                seg_states = states[i:i+4]\n",
    "                # skip if there is noise in this segment\n",
    "                if 'N' in ''.join(seg_states):\n",
    "                    print('Skip:')\n",
    "                    print(f'\\t{wav}, {label=}, {sig_qual=}, {state=}, {fr[i]}')\n",
    "                    print(f'\\t{seg_states}, frames:{fr[i:i+4]}')\n",
    "                    continue\n",
    "                if seg_states != ['S1', 'systole', 'S2', 'diastole']:\n",
    "                    raise Exception('Segment states are not correct!')\n",
    "                seg_starts.append(i)\n",
    "                seg_frames = frames[i:i+5] - frames[i] # include the start of the next segment, so we know the length of this segment\n",
    "                if wav in test_wavs:\n",
    "                    test_data['frames'].append(seg_frames)\n",
    "                    test_data['label'].append(label)\n",
    "                    test_data['wav'].append(wav)\n",
    "                    test_data['sig_qual'].append(sig_qual)\n",
    "                else:\n",
    "                    train_data['frames'].append(seg_frames)\n",
    "                    train_data['label'].append(label)\n",
    "                    train_data['wav'].append(wav)\n",
    "                    train_data['sig_qual'].append(sig_qual)\n",
    "        # save segments for each of the frequency bands         \n",
    "        for freq_band, pc_mean, pc_std in zip(freq_bands, pc_means, pc_stds):\n",
    "#             if freq_band != '25-400':\n",
    "#                 continue\n",
    "            FREQ = os.path.join(DATA, f'training-{dataset}', f'raw_filtBandIIR(ZP)4-{freq_band}_normRMS')\n",
    "            WAV = os.path.join(FREQ, f'{wav}_filtBandIIR(ZP)4-{freq_band}_normRMS.wav')\n",
    "            y, _ = librosa.load(WAV, sr = 2000)\n",
    "            y_hat = librosa.resample(y=y, orig_sr=2000, target_sr=1000)\n",
    "            # normalize the recording using mean and std of the train data that were calculated in advance and are now hardcoded\n",
    "            y_hat = (y_hat-pc_mean) / pc_std\n",
    "            c=0\n",
    "            for start in seg_starts:\n",
    "                seg_states = states[start:start+4]\n",
    "                seg_frames = frames[start:start+5] - frames[start]\n",
    "                seg_y = y_hat[frames[start]:frames[start+4]]\n",
    "                # zero pad the segments\n",
    "                if len(seg_y) > 2500:\n",
    "                    print(f'{wav} segment {start} is longer than 2500 samples')\n",
    "                seg_y = copy.deepcopy(seg_y)\n",
    "                seg_y.resize(2500)\n",
    "                if wav in test_wavs:\n",
    "                    test_data['data'][freq_band].append(seg_y)\n",
    "                else:\n",
    "                    train_data['data'][freq_band].append(seg_y)\n",
    "                if freq_band == '25-400':\n",
    "                    lens.append(len(seg_y))\n",
    "                    segs.append([wav, start])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd54e373",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "DATASET = os.path.join(DATA, f'zbytes_physionet_dataset{full_or_zeropad}.dat')\n",
    "dataset = {'train':train_data, 'test':test_data}\n",
    "utils.dict2file(dataset, DATASET)\n",
    "print(f'Dataset has been saved to {DATASET}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45004311",
   "metadata": {},
   "source": [
    "### Per channel normalization values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb660d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "stds = []\n",
    "# Find mean and std of the train data of the NOT-ZERO-PADDED train data\n",
    "for key in dataset['train']['data']:\n",
    "    freq_band = dataset['train']['data'][key]\n",
    "    freq_band = np.concatenate(freq_band).ravel()\n",
    "    mean = np.mean(freq_band)\n",
    "    means.append(mean)\n",
    "    std = np.std(freq_band)\n",
    "    stds.append(std)\n",
    "print(f'Per channel means: {means}')\n",
    "print(f'Per channel standard deviations: {stds}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "ds_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
