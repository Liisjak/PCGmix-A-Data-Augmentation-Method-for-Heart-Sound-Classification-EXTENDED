{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3ba33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import sklearn\n",
    "from sklearn import mixture\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "import time\n",
    "import timedelta\n",
    "import sys\n",
    "import random\n",
    "import cv2\n",
    "import importlib\n",
    "import argparse\n",
    "\n",
    "ROOT = '' # set\n",
    "sys.path.append(EOL)\n",
    "\n",
    "import classical\n",
    "import read_experiments\n",
    "import latent_space\n",
    "import saliency\n",
    "import augmentations2d\n",
    "import train_model\n",
    "import plotters\n",
    "import models2d\n",
    "import dataloader_umc2d\n",
    "import dataloader_physionet2d\n",
    "import utils\n",
    "\n",
    "# change the width of the cells\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776c12b7",
   "metadata": {},
   "source": [
    "### Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14392398",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = utils.check_folder(os.path.join(ROOT, 'data'))\n",
    "EXPERIMENTS = utils.check_folder(os.path.join(ROOT, 'experiments'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3852f6d1",
   "metadata": {},
   "source": [
    "### Setup parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b202d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch Training')\n",
    "parser.add_argument('--dataset', default='PhysioNet(spec)', type=str)\n",
    "parser.add_argument('--seed_data', default=3, type=int, help='dataset seed when selecting fraction of training set')\n",
    "parser.add_argument('--valid', default=False, type=bool, help='test model against validation set (when True) or against test set (when False)')\n",
    "parser.add_argument('--model', default='ResNet', type=str)\n",
    "parser.add_argument('--method', default='base', type=str)\n",
    "parser.add_argument('--depth', default=0, type=int)\n",
    "parser.add_argument('--n_fraction', default=1.0, type=float, help='fraction of train data to be used')\n",
    "parser.add_argument('--train_balance', default=True, type=bool, help='whether to balance train data')\n",
    "parser.add_argument('--num_epochs', default=100, type=int)\n",
    "parser.add_argument('--num_steps', default=100, type=int)\n",
    "parser.add_argument('--batch_size', default=128, type=int, help='train batchsize')\n",
    "parser.add_argument('--op', default='adam', type=str, help='optimizer')\n",
    "parser.add_argument('--lr', default=0.001, type=float, help='initial learning rate')\n",
    "parser.add_argument('--lr_max', default=0.0025, type=float, help='maximum allowed learning rate')\n",
    "parser.add_argument('--use_sched', default=True, type=bool, help='whether to use learning rate scheduler')\n",
    "parser.add_argument('--weight_decay', default=1e-4, type=float, help='weight decay (L2 penalty)')\n",
    "parser.add_argument('--grad_clip', default=0.1, type=float, help='gradient clipping to prevent exploding gradients')\n",
    "parser.add_argument('--seed', default=4)\n",
    "parser.add_argument('--num_classes', default=2, type=int, help='number of classes')\n",
    "parser.add_argument('--sample_rate', default=1000, type=int, help='signal sample rate')\n",
    "parser.add_argument('--num_channels', default=4, type=int, help='signal channel number')\n",
    "parser.add_argument('--sig_len', default=2500, type=int, help='signal length')\n",
    "parser.add_argument('--latent_space', default=False, type=bool, help='whether to calculate (and plot) latent space hidden features')\n",
    "parser.add_argument('--classical_space', default=False, type=bool, help='whether to calculate (and plot) classical features')\n",
    "parser.add_argument('--EXPERIMENTS', default = EXPERIMENTS, type=str, help='path to experiment results')\n",
    "parser.add_argument('-f') # dummy argument to prevent an error, since argparse is a module designed to parse the arguments passed from the command line\n",
    "args = parser.parse_args()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('Device set to: cuda')\n",
    "else: \n",
    "    device = torch.device('cpu')\n",
    "    print('Device set to: cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6548084b",
   "metadata": {},
   "source": [
    "## PhysioNet dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baab73f",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45282b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "args.dataset = 'PhysioNet(spec128)'\n",
    "DATASET = os.path.join(DATA, 'physionet', f'zbytes_physionet_spectrograms128_dataset_selection.dat')\n",
    "dataset = utils.file2dict(DATASET)\n",
    "print(f'Dataset {DATASET} has been loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a15c16",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea25a2b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(latent_space)\n",
    "importlib.reload(saliency)\n",
    "importlib.reload(augmentations2d)\n",
    "importlib.reload(train_model)\n",
    "importlib.reload(models2d)\n",
    "importlib.reload(plotters)\n",
    "importlib.reload(dataloader_physionet2d)\n",
    "importlib.reload(utils)\n",
    "\n",
    "args.model = 'resnet9'\n",
    "args.method = 'base'\n",
    "\n",
    "args.seed_data = 10005\n",
    "args.valid = False\n",
    "args.num_epochs = 10\n",
    "args.batch_size = 64\n",
    "args.lr_max = 0.01\n",
    "\n",
    "\n",
    "args.method = 'base'\n",
    "\n",
    "train_model.train_model(args, dataset, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cd700a",
   "metadata": {},
   "source": [
    "### Run baseline and augmentation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6eb021",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(latent_space)\n",
    "importlib.reload(saliency)\n",
    "importlib.reload(augmentations2d)\n",
    "importlib.reload(train_model)\n",
    "importlib.reload(models2d)\n",
    "importlib.reload(plotters)\n",
    "importlib.reload(dataloader_physionet2d)\n",
    "importlib.reload(utils)\n",
    "\n",
    "args.model='resnet9'\n",
    "\n",
    "aug_methods = [\n",
    "                 'durratiocutmix',\n",
    "                 'mixup(same)',\n",
    "                 'durratiomixup', # PCGmix\n",
    "                 'cutmix',\n",
    "                 'freqmask(0.1)',\n",
    "                 'timemask(0.1)',\n",
    "                 'cutout(0.25,0.25)',\n",
    "                 'latentmixup',\n",
    "                 'durmixfreqmask(0.1)',\n",
    "                 'durmixtimemask(0.1)',\n",
    "                 'durmixcutout(0.25,0.25)',\n",
    "                 '(saloptsum)durratiomixup',\n",
    "                 '(saloptenv)durratiomixup',\n",
    "                 '(saloptsum-1)durratiomixup',\n",
    "                 '(saloptenv-1)durratiomixup',\n",
    "                ]\n",
    "\n",
    "\n",
    "args.valid = False\n",
    "args.num_epochs = 50\n",
    "args.batch_size = 64\n",
    "args.lr_max = 0.01\n",
    "\n",
    "n_fractions = [0.015, 0.052, 0.1, 0.2, 0.3, 0.4, 0.6, 0.8, 1.0]\n",
    "n_fractions = [0.1]\n",
    "\n",
    "seeds_test = [1]\n",
    "for cm in aug_methods:   \n",
    "    #args.num_epochs = epoch\n",
    "    for n_fraction in n_fractions:\n",
    "        args.n_fraction = n_fraction\n",
    "        # select a cutmix probability grid that is limited based on the n_fraction\n",
    "        if n_fraction == 0.015:\n",
    "            aug_probas =  [1.0]\n",
    "            seed_datas = np.arange(1001001, 1001201, 1)\n",
    "        if n_fraction == 0.052:\n",
    "            aug_probas =  [1.0]\n",
    "            seed_datas = np.arange(1005001, 1005061, 1)\n",
    "        if n_fraction == 0.1:\n",
    "            aug_probas =  [1.0]\n",
    "            seed_datas = np.arange(1010001, 1010031, 1)\n",
    "            seed_datas = np.arange(1010001, 1010002, 1)\n",
    "        if n_fraction == 0.2:\n",
    "            aug_probas =  [0.6, 0.8, 1.0]\n",
    "            aug_probas =  [0.8]\n",
    "            seed_datas = np.arange(1020001, 1020016, 1)\n",
    "        if n_fraction == 0.3:\n",
    "            aug_probas =  [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "            seed_datas = np.arange(1030001, 1030011, 1)\n",
    "        if n_fraction == 0.4:\n",
    "            aug_probas =  [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "            seed_datas = np.arange(1040001, 1040009, 1)\n",
    "        if n_fraction == 0.6:\n",
    "            aug_probas =  [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "            seed_datas = np.arange(1060001, 1060006, 1)\n",
    "        if n_fraction == 0.8:\n",
    "            aug_probas =  [0.2, 0.4, 0.6]\n",
    "            seed_datas = np.arange(1080001, 1080005, 1)\n",
    "        if n_fraction == 1.0:\n",
    "            aug_probas =  [0.2, 0.4, 0.6]\n",
    "            seed_datas = [1100001]\n",
    "        if n_fraction == 1.0:\n",
    "            seeds_test = [1, 2, 3]\n",
    "        else:\n",
    "            seeds_test = [1]\n",
    "        for seed_data in seed_datas:\n",
    "            args.seed_data = seed_data\n",
    "            for seed in seeds_test:\n",
    "                args.seed = seed\n",
    "                args.method = 'base'\n",
    "                if utils.experiment_already_done(args):\n",
    "                    print(f'Already done: {args.seed_data=}, {args.seed=}, {args.valid=}, {args.method=}')\n",
    "                    continue\n",
    "                train_model.train_model(args, dataset, device)\n",
    "            for cp in aug_probas:\n",
    "                args.method = f'{cm}+{cp}'\n",
    "                for seed in seeds_test:\n",
    "                    args.seed = seed\n",
    "                    if utils.experiment_already_done(args):\n",
    "                        print(f'Already done: {args.seed_data=}, {args.seed=}, {args.valid=}, {args.method=}')\n",
    "                        continue\n",
    "                    train_model.train_model(args, dataset, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295dd145",
   "metadata": {},
   "source": [
    "## UMC dataset (proprietary chronic heart failure dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d67414a",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9704956",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "args.dataset = 'UMC(spec64)'\n",
    "DATASET = os.path.join(DATA, 'UMC', f'zbytes_UMC_dataset_spectrograms64.dat')\n",
    "dataset = utils.file2dict(DATASET)\n",
    "print(f'Dataset {DATASET} has been loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fc532c",
   "metadata": {},
   "source": [
    "### Run base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72df2b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(latent_space)\n",
    "importlib.reload(saliency)\n",
    "importlib.reload(augmentations2d)\n",
    "importlib.reload(train_model)\n",
    "importlib.reload(models2d)\n",
    "importlib.reload(plotters)\n",
    "importlib.reload(dataloader_physionet2d)\n",
    "importlib.reload(dataloader_umc2d)\n",
    "importlib.reload(utils)\n",
    "\n",
    "args.model='resnet9'\n",
    "\n",
    "lr_arr = [0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005, 0.00001]\n",
    "epochs_arr = [10]\n",
    "bs_arr = [128, 64, 32]\n",
    "\n",
    "seed_datas = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "args.seed = 1\n",
    "\n",
    "args.method = 'base'\n",
    "for batch_size in bs_arr:\n",
    "    args.batch_size = batch_size\n",
    "    for num_epochs in epochs_arr:\n",
    "        args.num_epochs = num_epochs\n",
    "        for lr_max in lr_arr:\n",
    "            args.lr_max = lr_max  \n",
    "            for seed_data in seed_datas:\n",
    "                args.seed_data = seed_data\n",
    "                if utils.experiment_already_done(args):\n",
    "                    continue\n",
    "                train_model.train_model(args, dataset, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb05d34",
   "metadata": {},
   "source": [
    "### Train with augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85d0de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(latent_space)\n",
    "importlib.reload(saliency)\n",
    "importlib.reload(augmentations2d)\n",
    "importlib.reload(train_model)\n",
    "importlib.reload(models2d)\n",
    "importlib.reload(plotters)\n",
    "importlib.reload(dataloader_physionet2d)\n",
    "importlib.reload(dataloader_umc2d)\n",
    "importlib.reload(utils)\n",
    "\n",
    "args.latent_space=False\n",
    "args.classical_space=False\n",
    "args.valid = False\n",
    "args.num_epochs = 50\n",
    "args.batch_size = 64\n",
    "args.lr_max = 0.01\n",
    "\n",
    "args.seed_data = 0\n",
    "args.model='resnet9'\n",
    "args.aug = False\n",
    "\n",
    "args.n_fraction = 1.0\n",
    "\n",
    "\n",
    "seed_datas = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "args.seed = 1\n",
    "\n",
    "aug_methods = [\n",
    "      'durratiomixup+1.0',\n",
    "      'durmixmagwarp(0.2,4)+1.0',\n",
    "        ]\n",
    "\n",
    "for am in aug_methods:\n",
    "    for seed_data in seed_datas:\n",
    "        args.seed_data = seed_data\n",
    "        args.method = 'base'\n",
    "        if utils.experiment_already_done(args):\n",
    "            continue\n",
    "        train_model.train_model(args, dataset, device)\n",
    "        args.method = am\n",
    "        if utils.experiment_already_done(args):\n",
    "            print(f'Already done: {args.seed_data=}, {args.seed=}, {args.valid=}, {args.method=}')\n",
    "            continue\n",
    "        train_model.train_model(args, dataset, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667de07b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "ds_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
